{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICIAR2018.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamdragle/ICIAR2018/blob/main/ICIAR2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsd21uQt_YQN"
      },
      "source": [
        "## <strong>ICIAR2018"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCSzyR51rM2R"
      },
      "source": [
        "# Download source và dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNHtgYKkALw5"
      },
      "source": [
        "!wget --save-cookies cookies.txt 'https://docs.google.com/uc?export=download&id=1qcOzX2qg5AxmHclFQGvP9l4ETEuBJdsY' -O- \\\n",
        "     | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1/p' > confirm.txt\n",
        "!wget --load-cookies cookies.txt -O ICIAR2018.zip \\\n",
        "     'https://docs.google.com/uc?export=download&id=1qcOzX2qg5AxmHclFQGvP9l4ETEuBJdsY&confirm='$(<confirm.txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKj8Xd8vrPkK"
      },
      "source": [
        "# Giải nén thư mục source code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWUtki_LNI4x"
      },
      "source": [
        "!unzip ICIAR2018.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFGFjs_vrSEI"
      },
      "source": [
        "# Chuyển đến thư mục chạy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe05TX8VOkft"
      },
      "source": [
        "%cd /content/content/drive/MyDrive/ColabNotebooks/ICIAR2018"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3JHQb8brjtG"
      },
      "source": [
        " # Cài đặt python requirements:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjFpr-f3rfWa"
      },
      "source": [
        "pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmsQOgkEriV4"
      },
      "source": [
        "pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2uY87f7r3Ge"
      },
      "source": [
        "# Testing\n",
        "Sử dụng tham số --testset-path để chỉ đến thư mục test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m7Qw0NhcHHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7675199e-311e-4fa8-d3a8-85068be3ade7"
      },
      "source": [
        "!python test.py --testset-path ./dataset/test "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------ Options -------------\n",
            "batch_size: 32\n",
            "beta1: 0.9\n",
            "beta2: 0.999\n",
            "channels: 1\n",
            "checkpoints_path: ./checkpoints\n",
            "cuda: False\n",
            "dataset_path: ./dataset\n",
            "debug: False\n",
            "ensemble: 1\n",
            "epochs: 30\n",
            "gpu_ids: 0\n",
            "log_interval: 50\n",
            "lr: 0.001\n",
            "network: 0\n",
            "no_cuda: False\n",
            "patch_stride: 256\n",
            "seed: 1\n",
            "test_batch_size: 32\n",
            "testset_path: ./dataset/test\n",
            "-------------- End ----------------\n",
            "\n",
            "Loading \"patch-wise\" model...\n",
            "Failed to load pre-trained network\n",
            "Loading \"patch-wise\" model...\n",
            "Failed to load pre-trained network\n",
            "\n",
            "tcmalloc: large alloc 1610612736 bytes == 0x2be74000 @  0x7f7da3188b6b 0x7f7da31a8379 0x7f7d4691274e 0x7f7d469147b6 0x7f7d80fd5271 0x7f7d80fc5489 0x7f7d80fcfaff 0x7f7d80fd3c3e 0x7f7d80fcccf6 0x7f7d80fcd77f 0x7f7d812925b6 0x7f7d812d679c 0x7f7d8094ae53 0x7f7d811f34bb 0x7f7d81103bbb 0x7f7d82648e0d 0x7f7d8094ae53 0x7f7d811f34bb 0x7f7d81103bbb 0x7f7d80ad3d00 0x7f7d8128b803 0x7f7d812d5be3 0x7f7d8094adba 0x7f7d811f1a1c 0x7f7d811024c4 0x7f7d80acae16 0x7f7d8128b50d 0x7f7d812d5aa3 0x7f7d8094af0f 0x7f7d811f0dc5 0x7f7d81101c1a\n",
            "tcmalloc: large alloc 1610612736 bytes == 0x8be74000 @  0x7f7da3188b6b 0x7f7da31a8379 0x7f7d4691274e 0x7f7d469147b6 0x7f7d80d68fa2 0x7f7d81053bd3 0x7f7d8102b207 0x7f7d810462dc 0x7f7d8102278a 0x7f7d8102b207 0x7f7d810462dc 0x7f7d811120dd 0x7f7d80fe0e74 0x7f7d80fcd84b 0x7f7d812925b6 0x7f7d812d679c 0x7f7d8094ae53 0x7f7d811f34bb 0x7f7d81103bbb 0x7f7d82648e0d 0x7f7d8094ae53 0x7f7d811f34bb 0x7f7d81103bbb 0x7f7d80ad3d00 0x7f7d8128b803 0x7f7d812d5be3 0x7f7d8094adba 0x7f7d811f1a1c 0x7f7d811024c4 0x7f7d80acae16 0x7f7d8128b50d\n",
            "tcmalloc: large alloc 1610612736 bytes == 0x2be74000 @  0x7f7da3188b6b 0x7f7da31a8379 0x7f7d4691274e 0x7f7d469147b6 0x7f7d80d68fa2 0x7f7d81053bd3 0x7f7d8102b207 0x7f7d810462dc 0x7f7d8102278a 0x7f7d8102b207 0x7f7d810462dc 0x7f7d811120dd 0x7f7d80d6820e 0x7f7d812d01ff 0x7f7d80935c1b 0x7f7d81202056 0x7f7d81114ba2 0x7f7d80c4d541 0x7f7d80c407f9 0x7f7d81082a0b 0x7f7d8107ba38 0x7f7d81216dbd 0x7f7d811309cc 0x7f7d826499aa 0x7f7d8107ba38 0x7f7d81216dbd 0x7f7d811309cc 0x7f7d80c3f05a 0x7f7d81289f05 0x7f7d812d55cc 0x7f7d812cccba\n",
            "tcmalloc: large alloc 1610612736 bytes == 0x8be74000 @  0x7f7da3188b6b 0x7f7da31a8379 0x7f7d4691274e 0x7f7d469147b6 0x7f7d80fd5271 0x7f7d80fc5489 0x7f7d80fc5e30 0x7f7d80fcfbda 0x7f7d80fd3b57 0x7f7d80fcccf6 0x7f7d80fcd77f 0x7f7d812925b6 0x7f7d812d679c 0x7f7d8094ae53 0x7f7d811f34bb 0x7f7d81103bbb 0x7f7d82648e0d 0x7f7d8094ae53 0x7f7d811f34bb 0x7f7d81103bbb 0x7f7d80ad3d00 0x7f7d8128b803 0x7f7d812d5be3 0x7f7d8094adba 0x7f7d811f1a1c 0x7f7d811024c4 0x7f7d80acae16 0x7f7d8128b50d 0x7f7d812d5aa3 0x7f7d8094af0f 0x7f7d811f0dc5\n",
            "00) Normal (87.5%) \t test0.tif\n",
            "01) Normal (100.0%) \t test1.tif\n",
            "02) Normal (100.0%) \t test10.tif\n",
            "03) Normal (100.0%) \t test11.tif\n",
            "04) Normal (100.0%) \t test12.tif\n",
            "05) Normal (100.0%) \t test13.tif\n",
            "06) Normal (87.5%) \t test14.tif\n",
            "07) Normal (100.0%) \t test15.tif\n",
            "08) Normal (100.0%) \t test16.tif\n",
            "09) Normal (100.0%) \t test17.tif\n",
            "10) Normal (100.0%) \t test18.tif\n",
            "11) Normal (100.0%) \t test19.tif\n",
            "12) Normal (87.5%) \t test2.tif\n",
            "13) Normal (100.0%) \t test20.tif\n",
            "14) Normal (100.0%) \t test21.tif\n",
            "15) Normal (100.0%) \t test22.tif\n",
            "16) Normal (100.0%) \t test23.tif\n",
            "17) Normal (87.5%) \t test24.tif\n",
            "18) Normal (100.0%) \t test25.tif\n",
            "19) Normal (100.0%) \t test26.tif\n",
            "20) Normal (87.5%) \t test27.tif\n",
            "21) Normal (100.0%) \t test28.tif\n",
            "22) Normal (100.0%) \t test29.tif\n",
            "23) Normal (100.0%) \t test3.tif\n",
            "24) Normal (100.0%) \t test30.tif\n",
            "25) Normal (87.5%) \t test31.tif\n",
            "26) Normal (100.0%) \t test32.tif\n",
            "27) Normal (100.0%) \t test33.tif\n",
            "28) Normal (100.0%) \t test34.tif\n",
            "29) Normal (100.0%) \t test35.tif\n",
            "30) Normal (100.0%) \t test36.tif\n",
            "31) Normal (87.5%) \t test37.tif\n",
            "32) Normal (87.5%) \t test38.tif\n",
            "33) Normal (100.0%) \t test39.tif\n",
            "34) Normal (100.0%) \t test4.tif\n",
            "35) Normal (100.0%) \t test40.tif\n",
            "36) Normal (100.0%) \t test41.tif\n",
            "37) Normal (100.0%) \t test42.tif\n",
            "38) Normal (100.0%) \t test43.tif\n",
            "39) Normal (100.0%) \t test44.tif\n",
            "40) Normal (100.0%) \t test45.tif\n",
            "41) Normal (100.0%) \t test46.tif\n",
            "42) Normal (100.0%) \t test47.tif\n",
            "43) Normal (87.5%) \t test48.tif\n",
            "44) Normal (100.0%) \t test49.tif\n",
            "45) Normal (100.0%) \t test5.tif\n",
            "46) Normal (100.0%) \t test50.tif\n",
            "47) Normal (100.0%) \t test51.tif\n",
            "48) Normal (100.0%) \t test52.tif\n",
            "49) Normal (100.0%) \t test53.tif\n",
            "50) Normal (100.0%) \t test54.tif\n",
            "51) Normal (100.0%) \t test55.tif\n",
            "52) Normal (87.5%) \t test56.tif\n",
            "53) Normal (100.0%) \t test57.tif\n",
            "54) Normal (100.0%) \t test58.tif\n",
            "55) Normal (100.0%) \t test59.tif\n",
            "56) Normal (100.0%) \t test6.tif\n",
            "57) Normal (87.5%) \t test60.tif\n",
            "58) Normal (62.5%) \t test61.tif\n",
            "59) Normal (100.0%) \t test62.tif\n",
            "60) Normal (87.5%) \t test63.tif\n",
            "61) Normal (100.0%) \t test64.tif\n",
            "62) Normal (100.0%) \t test65.tif\n",
            "63) Normal (87.5%) \t test66.tif\n",
            "64) Normal (87.5%) \t test67.tif\n",
            "65) Normal (87.5%) \t test68.tif\n",
            "66) Normal (87.5%) \t test69.tif\n",
            "67) Normal (100.0%) \t test7.tif\n",
            "68) Normal (100.0%) \t test70.tif\n",
            "69) Normal (100.0%) \t test71.tif\n",
            "70) Normal (100.0%) \t test72.tif\n",
            "71) Normal (100.0%) \t test73.tif\n",
            "72) Normal (100.0%) \t test74.tif\n",
            "73) Normal (100.0%) \t test75.tif\n",
            "74) Normal (100.0%) \t test76.tif\n",
            "75) Normal (100.0%) \t test77.tif\n",
            "76) Normal (100.0%) \t test78.tif\n",
            "77) Normal (100.0%) \t test79.tif\n",
            "78) Normal (100.0%) \t test8.tif\n",
            "79) Normal (87.5%) \t test80.tif\n",
            "80) Normal (87.5%) \t test81.tif\n",
            "81) Normal (100.0%) \t test82.tif\n",
            "82) Normal (100.0%) \t test83.tif\n",
            "83) Normal (100.0%) \t test84.tif\n",
            "84) Normal (100.0%) \t test85.tif\n",
            "85) Normal (100.0%) \t test86.tif\n",
            "86) Normal (100.0%) \t test87.tif\n",
            "87) Normal (100.0%) \t test88.tif\n",
            "88) Normal (100.0%) \t test89.tif\n",
            "89) Normal (100.0%) \t test9.tif\n",
            "90) Normal (87.5%) \t test90.tif\n",
            "91) Normal (100.0%) \t test91.tif\n",
            "92) Normal (100.0%) \t test92.tif\n",
            "93) Normal (100.0%) \t test93.tif\n",
            "94) Normal (100.0%) \t test94.tif\n",
            "95) Normal (87.5%) \t test95.tif\n",
            "96) Normal (100.0%) \t test96.tif\n",
            "97) Normal (100.0%) \t test97.tif\n",
            "98) Normal (87.5%) \t test98.tif\n",
            "99) Normal (100.0%) \t test99.tif\n",
            "\n",
            "Inference time: 1:04:59.399501\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQIWxZCskU2"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A8_FEIYaX9o",
        "outputId": "642b33d6-86f8-4c34-b3de-aaa3dceef920"
      },
      "source": [
        "!python train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------ Options -------------\n",
            "batch_size: 32\n",
            "beta1: 0.9\n",
            "beta2: 0.999\n",
            "channels: 1\n",
            "checkpoints_path: ./checkpoints\n",
            "cuda: True\n",
            "dataset_path: ./dataset\n",
            "debug: False\n",
            "ensemble: 1\n",
            "epochs: 30\n",
            "gpu_ids: 0\n",
            "log_interval: 50\n",
            "lr: 0.001\n",
            "network: 0\n",
            "no_cuda: False\n",
            "patch_stride: 256\n",
            "seed: 1\n",
            "test_batch_size: 32\n",
            "testset_path: \n",
            "-------------- End ----------------\n",
            "\n",
            "Loading \"patch-wise\" model...\n",
            "Start training patch-wise network: 2020/12/17 03:44\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "Epoch: 1/30 [1600/224000 (1%)]\tLoss: 0.000714, Accuracy: 99.45%\n",
            "Epoch: 1/30 [3200/224000 (1%)]\tLoss: 0.000665, Accuracy: 99.38%\n",
            "Epoch: 1/30 [4800/224000 (2%)]\tLoss: 0.025150, Accuracy: 99.28%\n",
            "Epoch: 1/30 [6400/224000 (3%)]\tLoss: 0.000596, Accuracy: 99.36%\n",
            "Epoch: 1/30 [8000/224000 (4%)]\tLoss: 0.004077, Accuracy: 99.35%\n",
            "Epoch: 1/30 [9600/224000 (4%)]\tLoss: 0.023509, Accuracy: 99.34%\n",
            "Epoch: 1/30 [11200/224000 (5%)]\tLoss: 0.013015, Accuracy: 99.33%\n",
            "Epoch: 1/30 [12800/224000 (6%)]\tLoss: 0.014411, Accuracy: 99.35%\n",
            "Epoch: 1/30 [14400/224000 (6%)]\tLoss: 0.055929, Accuracy: 99.36%\n",
            "Epoch: 1/30 [16000/224000 (7%)]\tLoss: 0.009963, Accuracy: 99.39%\n",
            "Epoch: 1/30 [17600/224000 (8%)]\tLoss: 0.103974, Accuracy: 99.40%\n",
            "Epoch: 1/30 [19200/224000 (9%)]\tLoss: 0.001174, Accuracy: 99.39%\n",
            "Epoch: 1/30 [20800/224000 (9%)]\tLoss: 0.018977, Accuracy: 99.38%\n",
            "Epoch: 1/30 [22400/224000 (10%)]\tLoss: 0.009448, Accuracy: 99.39%\n",
            "Epoch: 1/30 [24000/224000 (11%)]\tLoss: 0.312697, Accuracy: 99.40%\n",
            "Epoch: 1/30 [25600/224000 (11%)]\tLoss: 0.043357, Accuracy: 99.40%\n",
            "Epoch: 1/30 [27200/224000 (12%)]\tLoss: 0.000289, Accuracy: 99.41%\n",
            "Epoch: 1/30 [28800/224000 (13%)]\tLoss: 0.001166, Accuracy: 99.41%\n",
            "Epoch: 1/30 [30400/224000 (14%)]\tLoss: 0.003456, Accuracy: 99.42%\n",
            "Epoch: 1/30 [32000/224000 (14%)]\tLoss: 0.000110, Accuracy: 99.43%\n",
            "Epoch: 1/30 [33600/224000 (15%)]\tLoss: 0.032746, Accuracy: 99.43%\n",
            "Epoch: 1/30 [35200/224000 (16%)]\tLoss: 0.000197, Accuracy: 99.42%\n",
            "Epoch: 1/30 [36800/224000 (16%)]\tLoss: 0.001517, Accuracy: 99.42%\n",
            "Epoch: 1/30 [38400/224000 (17%)]\tLoss: 0.009277, Accuracy: 99.42%\n",
            "Epoch: 1/30 [40000/224000 (18%)]\tLoss: 0.009074, Accuracy: 99.43%\n",
            "Epoch: 1/30 [41600/224000 (19%)]\tLoss: 0.000524, Accuracy: 99.42%\n",
            "Epoch: 1/30 [43200/224000 (19%)]\tLoss: 0.120354, Accuracy: 99.43%\n",
            "Epoch: 1/30 [44800/224000 (20%)]\tLoss: 0.096678, Accuracy: 99.40%\n",
            "Epoch: 1/30 [46400/224000 (21%)]\tLoss: 0.002514, Accuracy: 99.39%\n",
            "Epoch: 1/30 [48000/224000 (21%)]\tLoss: 0.004943, Accuracy: 99.39%\n",
            "Epoch: 1/30 [49600/224000 (22%)]\tLoss: 0.009405, Accuracy: 99.40%\n",
            "Epoch: 1/30 [51200/224000 (23%)]\tLoss: 0.011368, Accuracy: 99.40%\n",
            "Epoch: 1/30 [52800/224000 (24%)]\tLoss: 0.001298, Accuracy: 99.40%\n",
            "Epoch: 1/30 [54400/224000 (24%)]\tLoss: 0.005556, Accuracy: 99.41%\n",
            "Epoch: 1/30 [56000/224000 (25%)]\tLoss: 0.048762, Accuracy: 99.41%\n",
            "Epoch: 1/30 [57600/224000 (26%)]\tLoss: 0.012398, Accuracy: 99.41%\n",
            "Epoch: 1/30 [59200/224000 (26%)]\tLoss: 0.001875, Accuracy: 99.42%\n",
            "Epoch: 1/30 [60800/224000 (27%)]\tLoss: 0.000841, Accuracy: 99.41%\n",
            "Epoch: 1/30 [62400/224000 (28%)]\tLoss: 0.110119, Accuracy: 99.41%\n",
            "Epoch: 1/30 [64000/224000 (29%)]\tLoss: 0.074544, Accuracy: 99.40%\n",
            "Epoch: 1/30 [65600/224000 (29%)]\tLoss: 0.004006, Accuracy: 99.40%\n",
            "Epoch: 1/30 [67200/224000 (30%)]\tLoss: 0.000178, Accuracy: 99.40%\n",
            "Epoch: 1/30 [68800/224000 (31%)]\tLoss: 0.002569, Accuracy: 99.39%\n",
            "Epoch: 1/30 [70400/224000 (31%)]\tLoss: 0.011832, Accuracy: 99.37%\n",
            "Epoch: 1/30 [72000/224000 (32%)]\tLoss: 0.021482, Accuracy: 99.37%\n",
            "Epoch: 1/30 [73600/224000 (33%)]\tLoss: 0.008173, Accuracy: 99.36%\n",
            "Epoch: 1/30 [75200/224000 (34%)]\tLoss: 0.001769, Accuracy: 99.36%\n",
            "Epoch: 1/30 [76800/224000 (34%)]\tLoss: 0.001853, Accuracy: 99.35%\n",
            "Epoch: 1/30 [78400/224000 (35%)]\tLoss: 0.016733, Accuracy: 99.35%\n",
            "Epoch: 1/30 [80000/224000 (36%)]\tLoss: 0.010794, Accuracy: 99.35%\n",
            "Epoch: 1/30 [81600/224000 (36%)]\tLoss: 0.089982, Accuracy: 99.36%\n",
            "Epoch: 1/30 [83200/224000 (37%)]\tLoss: 0.000945, Accuracy: 99.37%\n",
            "Epoch: 1/30 [84800/224000 (38%)]\tLoss: 0.000900, Accuracy: 99.37%\n",
            "Epoch: 1/30 [86400/224000 (39%)]\tLoss: 0.041745, Accuracy: 99.37%\n",
            "Epoch: 1/30 [88000/224000 (39%)]\tLoss: 0.001941, Accuracy: 99.37%\n",
            "Epoch: 1/30 [89600/224000 (40%)]\tLoss: 0.001975, Accuracy: 99.37%\n",
            "Epoch: 1/30 [91200/224000 (41%)]\tLoss: 0.004409, Accuracy: 99.38%\n",
            "Epoch: 1/30 [92800/224000 (41%)]\tLoss: 0.004096, Accuracy: 99.38%\n",
            "Epoch: 1/30 [94400/224000 (42%)]\tLoss: 0.020498, Accuracy: 99.38%\n",
            "Epoch: 1/30 [96000/224000 (43%)]\tLoss: 0.000101, Accuracy: 99.38%\n",
            "Epoch: 1/30 [97600/224000 (44%)]\tLoss: 0.002002, Accuracy: 99.38%\n",
            "Epoch: 1/30 [99200/224000 (44%)]\tLoss: 0.074012, Accuracy: 99.38%\n",
            "Epoch: 1/30 [100800/224000 (45%)]\tLoss: 0.001290, Accuracy: 99.38%\n",
            "Epoch: 1/30 [102400/224000 (46%)]\tLoss: 0.000670, Accuracy: 99.38%\n",
            "Epoch: 1/30 [104000/224000 (46%)]\tLoss: 0.000081, Accuracy: 99.38%\n",
            "Epoch: 1/30 [105600/224000 (47%)]\tLoss: 0.000102, Accuracy: 99.38%\n",
            "Epoch: 1/30 [107200/224000 (48%)]\tLoss: 0.006999, Accuracy: 99.38%\n",
            "Epoch: 1/30 [108800/224000 (49%)]\tLoss: 0.001885, Accuracy: 99.39%\n",
            "Epoch: 1/30 [110400/224000 (49%)]\tLoss: 0.015543, Accuracy: 99.39%\n",
            "Epoch: 1/30 [112000/224000 (50%)]\tLoss: 0.133336, Accuracy: 99.39%\n",
            "Epoch: 1/30 [113600/224000 (51%)]\tLoss: 0.032161, Accuracy: 99.38%\n",
            "Epoch: 1/30 [115200/224000 (51%)]\tLoss: 0.023800, Accuracy: 99.38%\n",
            "Epoch: 1/30 [116800/224000 (52%)]\tLoss: 0.004472, Accuracy: 99.38%\n",
            "Epoch: 1/30 [118400/224000 (53%)]\tLoss: 0.001912, Accuracy: 99.38%\n",
            "Epoch: 1/30 [120000/224000 (54%)]\tLoss: 0.004534, Accuracy: 99.38%\n",
            "Epoch: 1/30 [121600/224000 (54%)]\tLoss: 0.005954, Accuracy: 99.38%\n",
            "Epoch: 1/30 [123200/224000 (55%)]\tLoss: 0.149104, Accuracy: 99.37%\n",
            "Epoch: 1/30 [124800/224000 (56%)]\tLoss: 0.023918, Accuracy: 99.36%\n",
            "Epoch: 1/30 [126400/224000 (56%)]\tLoss: 0.002286, Accuracy: 99.37%\n",
            "Epoch: 1/30 [128000/224000 (57%)]\tLoss: 0.040598, Accuracy: 99.37%\n",
            "Epoch: 1/30 [129600/224000 (58%)]\tLoss: 0.000378, Accuracy: 99.38%\n",
            "Epoch: 1/30 [131200/224000 (59%)]\tLoss: 0.020301, Accuracy: 99.38%\n",
            "Epoch: 1/30 [132800/224000 (59%)]\tLoss: 0.029551, Accuracy: 99.38%\n",
            "Epoch: 1/30 [134400/224000 (60%)]\tLoss: 0.001719, Accuracy: 99.38%\n",
            "Epoch: 1/30 [136000/224000 (61%)]\tLoss: 0.003067, Accuracy: 99.38%\n",
            "Epoch: 1/30 [137600/224000 (61%)]\tLoss: 0.000080, Accuracy: 99.38%\n",
            "Epoch: 1/30 [139200/224000 (62%)]\tLoss: 0.000205, Accuracy: 99.38%\n",
            "Epoch: 1/30 [140800/224000 (63%)]\tLoss: 0.002002, Accuracy: 99.38%\n",
            "Epoch: 1/30 [142400/224000 (64%)]\tLoss: 0.000119, Accuracy: 99.38%\n",
            "Epoch: 1/30 [144000/224000 (64%)]\tLoss: 0.034444, Accuracy: 99.38%\n",
            "Epoch: 1/30 [145600/224000 (65%)]\tLoss: 0.000463, Accuracy: 99.38%\n",
            "Epoch: 1/30 [147200/224000 (66%)]\tLoss: 0.003844, Accuracy: 99.38%\n",
            "Epoch: 1/30 [148800/224000 (66%)]\tLoss: 0.000173, Accuracy: 99.38%\n",
            "Epoch: 1/30 [150400/224000 (67%)]\tLoss: 0.000145, Accuracy: 99.38%\n",
            "Epoch: 1/30 [152000/224000 (68%)]\tLoss: 0.003840, Accuracy: 99.38%\n",
            "Epoch: 1/30 [153600/224000 (69%)]\tLoss: 0.070069, Accuracy: 99.38%\n",
            "Epoch: 1/30 [155200/224000 (69%)]\tLoss: 0.000332, Accuracy: 99.38%\n",
            "Epoch: 1/30 [156800/224000 (70%)]\tLoss: 0.066874, Accuracy: 99.38%\n",
            "Epoch: 1/30 [158400/224000 (71%)]\tLoss: 0.002012, Accuracy: 99.38%\n",
            "Epoch: 1/30 [160000/224000 (71%)]\tLoss: 0.000201, Accuracy: 99.38%\n",
            "Epoch: 1/30 [161600/224000 (72%)]\tLoss: 0.021198, Accuracy: 99.38%\n",
            "Epoch: 1/30 [163200/224000 (73%)]\tLoss: 0.087566, Accuracy: 99.38%\n",
            "Epoch: 1/30 [164800/224000 (74%)]\tLoss: 0.006412, Accuracy: 99.38%\n",
            "Epoch: 1/30 [166400/224000 (74%)]\tLoss: 0.003065, Accuracy: 99.38%\n",
            "Epoch: 1/30 [168000/224000 (75%)]\tLoss: 0.003604, Accuracy: 99.38%\n",
            "Epoch: 1/30 [169600/224000 (76%)]\tLoss: 0.002994, Accuracy: 99.38%\n",
            "Epoch: 1/30 [171200/224000 (76%)]\tLoss: 0.027763, Accuracy: 99.38%\n",
            "Epoch: 1/30 [172800/224000 (77%)]\tLoss: 0.036885, Accuracy: 99.38%\n",
            "Epoch: 1/30 [174400/224000 (78%)]\tLoss: 0.009356, Accuracy: 99.38%\n",
            "Epoch: 1/30 [176000/224000 (79%)]\tLoss: 0.027536, Accuracy: 99.39%\n",
            "Epoch: 1/30 [177600/224000 (79%)]\tLoss: 0.009850, Accuracy: 99.38%\n",
            "Epoch: 1/30 [179200/224000 (80%)]\tLoss: 0.000515, Accuracy: 99.39%\n",
            "Epoch: 1/30 [180800/224000 (81%)]\tLoss: 0.000124, Accuracy: 99.39%\n",
            "Epoch: 1/30 [182400/224000 (81%)]\tLoss: 0.006349, Accuracy: 99.39%\n",
            "Epoch: 1/30 [184000/224000 (82%)]\tLoss: 0.035281, Accuracy: 99.39%\n",
            "Epoch: 1/30 [185600/224000 (83%)]\tLoss: 0.013410, Accuracy: 99.39%\n",
            "Epoch: 1/30 [187200/224000 (84%)]\tLoss: 0.007519, Accuracy: 99.40%\n",
            "Epoch: 1/30 [188800/224000 (84%)]\tLoss: 0.038453, Accuracy: 99.40%\n",
            "Epoch: 1/30 [190400/224000 (85%)]\tLoss: 0.000989, Accuracy: 99.40%\n",
            "Epoch: 1/30 [192000/224000 (86%)]\tLoss: 0.022566, Accuracy: 99.39%\n",
            "Epoch: 1/30 [193600/224000 (86%)]\tLoss: 0.000423, Accuracy: 99.39%\n",
            "Epoch: 1/30 [195200/224000 (87%)]\tLoss: 0.001701, Accuracy: 99.40%\n",
            "Epoch: 1/30 [196800/224000 (88%)]\tLoss: 0.001657, Accuracy: 99.39%\n",
            "Epoch: 1/30 [198400/224000 (89%)]\tLoss: 0.000669, Accuracy: 99.39%\n",
            "Epoch: 1/30 [200000/224000 (89%)]\tLoss: 0.027687, Accuracy: 99.39%\n",
            "Epoch: 1/30 [201600/224000 (90%)]\tLoss: 0.014217, Accuracy: 99.40%\n",
            "Epoch: 1/30 [203200/224000 (91%)]\tLoss: 0.006069, Accuracy: 99.40%\n",
            "Epoch: 1/30 [204800/224000 (91%)]\tLoss: 0.003177, Accuracy: 99.40%\n",
            "Epoch: 1/30 [206400/224000 (92%)]\tLoss: 0.137479, Accuracy: 99.40%\n",
            "Epoch: 1/30 [208000/224000 (93%)]\tLoss: 0.005677, Accuracy: 99.39%\n",
            "Epoch: 1/30 [209600/224000 (94%)]\tLoss: 0.041676, Accuracy: 99.39%\n",
            "Epoch: 1/30 [211200/224000 (94%)]\tLoss: 0.018586, Accuracy: 99.39%\n",
            "Epoch: 1/30 [212800/224000 (95%)]\tLoss: 0.001032, Accuracy: 99.39%\n",
            "Epoch: 1/30 [214400/224000 (96%)]\tLoss: 0.016387, Accuracy: 99.38%\n",
            "Epoch: 1/30 [216000/224000 (96%)]\tLoss: 0.010650, Accuracy: 99.38%\n",
            "Epoch: 1/30 [217600/224000 (97%)]\tLoss: 0.074244, Accuracy: 99.38%\n",
            "Epoch: 1/30 [219200/224000 (98%)]\tLoss: 0.000080, Accuracy: 99.38%\n",
            "Epoch: 1/30 [220800/224000 (99%)]\tLoss: 0.006024, Accuracy: 99.39%\n",
            "Epoch: 1/30 [222400/224000 (99%)]\tLoss: 0.000436, Accuracy: 99.39%\n",
            "\n",
            "End of epoch 1, time: 7:19:28.659996\n",
            "\n",
            "Evaluating....\n",
            "Average loss: 0.0012, Accuracy: 3500/3500 (100%)\n",
            "Normal:  \t Precision: 1.00,  Recall: 1.00,  F1: 1.00\n",
            "Benign:  \t Precision: 1.00,  Recall: 1.00,  F1: 1.00\n",
            "InSitu:  \t Precision: 1.00,  Recall: 1.00,  F1: 1.00\n",
            "Invasive:  \t Precision: 1.00,  Recall: 1.00,  F1: 1.00\n",
            "\n",
            "Saving model to \"./checkpoints/weights_pw1.pth\"\n",
            "Epoch: 2/30 [1600/224000 (1%)]\tLoss: 0.000495, Accuracy: 99.51%\n",
            "Epoch: 2/30 [3200/224000 (1%)]\tLoss: 0.045127, Accuracy: 99.47%\n",
            "Epoch: 2/30 [4800/224000 (2%)]\tLoss: 0.026057, Accuracy: 99.40%\n",
            "Epoch: 2/30 [6400/224000 (3%)]\tLoss: 0.002788, Accuracy: 99.35%\n",
            "Epoch: 2/30 [8000/224000 (4%)]\tLoss: 0.000660, Accuracy: 99.39%\n",
            "Epoch: 2/30 [9600/224000 (4%)]\tLoss: 0.002995, Accuracy: 99.45%\n",
            "Epoch: 2/30 [11200/224000 (5%)]\tLoss: 0.000263, Accuracy: 99.47%\n",
            "Epoch: 2/30 [12800/224000 (6%)]\tLoss: 0.127584, Accuracy: 99.44%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4MdlgaGsUnf"
      },
      "source": [
        "# Validation & ROC Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHG_yFfptB9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab6264d-b411-46d7-fc83-13f1f30f53cf"
      },
      "source": [
        "!python validate.py"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------ Options -------------\n",
            "batch_size: 32\n",
            "beta1: 0.9\n",
            "beta2: 0.999\n",
            "channels: 1\n",
            "checkpoints_path: ./checkpoints\n",
            "cuda: False\n",
            "dataset_path: ./dataset\n",
            "debug: False\n",
            "ensemble: 1\n",
            "epochs: 30\n",
            "gpu_ids: 0\n",
            "log_interval: 50\n",
            "lr: 0.001\n",
            "network: 0\n",
            "no_cuda: False\n",
            "patch_stride: 256\n",
            "seed: 1\n",
            "test_batch_size: 32\n",
            "testset_path: \n",
            "-------------- End ----------------\n",
            "\n",
            "Loading \"patch-wise\" model...\n",
            "Failed to load pre-trained network\n",
            "\n",
            "Evaluating....\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "Average loss: 1.4460, Accuracy: 709/3500 (20%)\n",
            "Normal:  \t Precision: 0.19,  Recall: 0.10,  F1: 0.13\n",
            "Benign:  \t Precision: 0.00,  Recall: 0.00,  F1: 0.00\n",
            "InSitu:  \t Precision: 0.00,  Recall: 0.00,  F1: 0.00\n",
            "Invasive:  \t Precision: 0.20,  Recall: 0.91,  F1: 0.33\n",
            "\n",
            "Loading \"patch-wise\" model...\n",
            "Failed to load pre-trained network\n",
            "Loading \"patch-wise\" model...\n",
            "Failed to load pre-trained network\n",
            "tcmalloc: large alloc 1610612736 bytes == 0x65658000 @  0x7f90b3455b6b 0x7f90b3475379 0x7f9056bdf74e 0x7f9056be17b6 0x7f90912a2271 0x7f9091292489 0x7f909129caff 0x7f90912a0c3e 0x7f9091299cf6 0x7f909129a77f 0x7f909155f5b6 0x7f90915a379c 0x7f9090c17e53 0x7f90914c04bb 0x7f90913d0bbb 0x7f9092915e0d 0x7f9090c17e53 0x7f90914c04bb 0x7f90913d0bbb 0x7f9090da0d00 0x7f9091558803 0x7f90915a2be3 0x7f9090c17dba 0x7f90914bea1c 0x7f90913cf4c4 0x7f9090d97e16 0x7f909155850d 0x7f90915a2aa3 0x7f9090c17f0f 0x7f90914bddc5 0x7f90913cec1a\n",
            "tcmalloc: large alloc 1610612736 bytes == 0xc5658000 @  0x7f90b3455b6b 0x7f90b3475379 0x7f9056bdf74e 0x7f9056be17b6 0x7f9091035fa2 0x7f9091320bd3 0x7f90912f8207 0x7f90913132dc 0x7f90912ef78a 0x7f90912f8207 0x7f90913132dc 0x7f90913df0dd 0x7f90912ade74 0x7f909129a84b 0x7f909155f5b6 0x7f90915a379c 0x7f9090c17e53 0x7f90914c04bb 0x7f90913d0bbb 0x7f9092915e0d 0x7f9090c17e53 0x7f90914c04bb 0x7f90913d0bbb 0x7f9090da0d00 0x7f9091558803 0x7f90915a2be3 0x7f9090c17dba 0x7f90914bea1c 0x7f90913cf4c4 0x7f9090d97e16 0x7f909155850d\n",
            "tcmalloc: large alloc 1610612736 bytes == 0x65658000 @  0x7f90b3455b6b 0x7f90b3475379 0x7f9056bdf74e 0x7f9056be17b6 0x7f9091035fa2 0x7f9091320bd3 0x7f90912f8207 0x7f90913132dc 0x7f90912ef78a 0x7f90912f8207 0x7f90913132dc 0x7f90913df0dd 0x7f909103520e 0x7f909159d1ff 0x7f9090c02c1b 0x7f90914cf056 0x7f90913e1ba2 0x7f9090f1a541 0x7f9090f0d7f9 0x7f909134fa0b 0x7f9091348a38 0x7f90914e3dbd 0x7f90913fd9cc 0x7f90929169aa 0x7f9091348a38 0x7f90914e3dbd 0x7f90913fd9cc 0x7f9090f0c05a 0x7f9091556f05 0x7f90915a25cc 0x7f9091599cba\n",
            "tcmalloc: large alloc 1610612736 bytes == 0xc5658000 @  0x7f90b3455b6b 0x7f90b3475379 0x7f9056bdf74e 0x7f9056be17b6 0x7f90912a2271 0x7f9091292489 0x7f9091292e30 0x7f909129cbda 0x7f90912a0b57 0x7f9091299cf6 0x7f909129a77f 0x7f909155f5b6 0x7f90915a379c 0x7f9090c17e53 0x7f90914c04bb 0x7f90913d0bbb 0x7f9092915e0d 0x7f9090c17e53 0x7f90914c04bb 0x7f90913d0bbb 0x7f9090da0d00 0x7f9091558803 0x7f90915a2be3 0x7f9090c17dba 0x7f90914bea1c 0x7f90913cf4c4 0x7f9090d97e16 0x7f909155850d 0x7f90915a2aa3 0x7f9090c17f0f 0x7f90914bddc5\n",
            "80 images loaded\n",
            "\n",
            "Evaluating....\n",
            "/content/ICIAR2018/src/models.py:355: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  output = self.network(Variable(images, volatile=True))\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "Average loss: 1.3863, Accuracy: 23/100 (23%)\n",
            "Normal:  \t Precision: 0.18,  Recall: 0.75,  F1: 0.29\n",
            "Benign:  \t Precision: 0.44,  Recall: 0.27,  F1: 0.33\n",
            "InSitu:  \t Precision: 0.00,  Recall: 0.00,  F1: 0.00\n",
            "Invasive:  \t Precision: 0.00,  Recall: 0.00,  F1: 0.00\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uArlSA_R9iun"
      },
      "source": [
        ""
      ]
    }
  ]
}